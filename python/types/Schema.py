# Copyright (c), CommunityLogiq Software
# 
# THIS FILE IS AUTOGENERATED, DO NOT EDIT

from dataclasses import dataclass
from enum import Enum
from flatbuffers.table import Table
from flatbuffers.builder import Builder
from flatbuffers.util import RemoveSizePrefix
from typing import Union, List, Optional, Self, Tuple
from .generated.Binary import Binary as FbsBinary
from .generated.Bool import Bool as FbsBool
from .generated.Buffer import Buffer as FbsBuffer
from .generated.Date import Date as FbsDate
from .generated.Decimal import Decimal as FbsDecimal
from .generated.DictionaryEncoding import DictionaryEncoding as FbsDictionaryEncoding
from .generated.Duration import Duration as FbsDuration
from .generated.Field import Field as FbsField
from .generated.FixedSizeBinary import FixedSizeBinary as FbsFixedSizeBinary
from .generated.FixedSizeList import FixedSizeList as FbsFixedSizeList
from .generated.FloatingPoint import FloatingPoint as FbsFloatingPoint
from .generated.Int import Int as FbsInt
from .generated.Interval import Interval as FbsInterval
from .generated.KeyValue import KeyValue as FbsKeyValue
from .generated.LargeBinary import LargeBinary as FbsLargeBinary
from .generated.LargeList import LargeList as FbsLargeList
from .generated.LargeUtf8 import LargeUtf8 as FbsLargeUtf8
from .generated.List import List as FbsList
from .generated.Map import Map as FbsMap
from .generated.Null import Null as FbsNull
from .generated.Schema import Schema as FbsSchema
from .generated.Struct_ import Struct_ as FbsStruct_
from .generated.Time import Time as FbsTime
from .generated.Timestamp import Timestamp as FbsTimestamp
from .generated.Union import Union as FbsUnion
from .generated.Utf8 import Utf8 as FbsUtf8
from .generated.Type import Type as FbsType

class DateUnit(Enum):
    DAY = 0
    MILLISECOND = 1

class DictionaryKind(Enum):
    DenseArray = 0

class Endianness(Enum):
    Little = 0
    Big = 1

class Feature(Enum):
    UNUSED = 0
    DICTIONARY_REPLACEMENT = 1
    COMPRESSED_BODY = 2

class IntervalUnit(Enum):
    YEAR_MONTH = 0
    DAY_TIME = 1
    MONTH_DAY_NANO = 2

class MetadataVersion(Enum):
    V1 = 0
    V2 = 1
    V3 = 2
    V4 = 3
    V5 = 4

class Precision(Enum):
    HALF = 0
    SINGLE = 1
    DOUBLE = 2

class TimeUnit(Enum):
    SECOND = 0
    MILLISECOND = 1
    MICROSECOND = 2
    NANOSECOND = 3

class UnionMode(Enum):
    Sparse = 0
    Dense = 1


@dataclass
class Null:
    """ These are stored in the flatbuffer in the Type union below
    """

    @classmethod
    def from_fbs(cls, o: FbsNull) -> Self:
        return cls()

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsNull.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Null import (
            Start,
            End,
        )
        
        Start(builder)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        return cls()

    def __eq__(self, other) -> bool:
        eq = True

        return eq

@dataclass
class Int:
    bitWidth: "int"

    is_signed: "bool"

    @classmethod
    def from_fbs(cls, o: FbsInt) -> Self:
        bitWidth = o.BitWidth()
        is_signed = o.IsSigned()
        return cls(bitWidth, is_signed)

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsInt.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Int import (
            Start,
            AddBitWidth,
            AddIsSigned,
            End,
        )
        
        Start(builder)
        AddBitWidth(builder, self.bitWidth)
        AddIsSigned(builder, self.is_signed)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        bitWidth = 0
        is_signed = False
        return cls(bitWidth, is_signed)

    def __eq__(self, other) -> bool:
        eq = True
        eq = eq and self.bitWidth == other.bitWidth
        eq = eq and self.is_signed == other.is_signed

        return eq

@dataclass
class FloatingPoint:
    precision: "Precision"

    @classmethod
    def from_fbs(cls, o: FbsFloatingPoint) -> Self:
        precision = Precision(o.Precision())
        return cls(precision)

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsFloatingPoint.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.FloatingPoint import (
            Start,
            AddPrecision,
            End,
        )
        
        Start(builder)
        AddPrecision(builder, self.precision.value)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        precision = Precision(0)
        return cls(precision)

    def __eq__(self, other) -> bool:
        eq = True
        eq = eq and self.precision == other.precision

        return eq

@dataclass
class Binary:
    """ Opaque binary data
    """

    @classmethod
    def from_fbs(cls, o: FbsBinary) -> Self:
        return cls()

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsBinary.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Binary import (
            Start,
            End,
        )
        
        Start(builder)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        return cls()

    def __eq__(self, other) -> bool:
        eq = True

        return eq

@dataclass
class Utf8:
    """ Unicode with UTF-8 encoding
    """

    @classmethod
    def from_fbs(cls, o: FbsUtf8) -> Self:
        return cls()

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsUtf8.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Utf8 import (
            Start,
            End,
        )
        
        Start(builder)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        return cls()

    def __eq__(self, other) -> bool:
        eq = True

        return eq

@dataclass
class Bool:
    @classmethod
    def from_fbs(cls, o: FbsBool) -> Self:
        return cls()

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsBool.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Bool import (
            Start,
            End,
        )
        
        Start(builder)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        return cls()

    def __eq__(self, other) -> bool:
        eq = True

        return eq

@dataclass
class Decimal:
    """ Exact decimal value represented as an integer value in two's
     complement. Currently only 128-bit (16-byte) and 256-bit (32-byte) integers
     are used. The representation uses the endianness indicated
     in the Schema.
    """

    # Number of bits per value. The only accepted widths are 128 and 256.
    # We use bitWidth for consistency with Int::bitWidth.
    bitWidth: "int"

    # Total number of decimal digits
    precision: "int"

    # Number of digits after the decimal point "."
    scale: "int"

    @classmethod
    def from_fbs(cls, o: FbsDecimal) -> Self:
        bitWidth = o.BitWidth()
        precision = o.Precision()
        scale = o.Scale()
        return cls(bitWidth, precision, scale)

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsDecimal.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Decimal import (
            Start,
            AddBitWidth,
            AddPrecision,
            AddScale,
            End,
        )
        
        Start(builder)
        AddBitWidth(builder, self.bitWidth)
        AddPrecision(builder, self.precision)
        AddScale(builder, self.scale)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        bitWidth = 0
        precision = 0
        scale = 0
        return cls(bitWidth, precision, scale)

    def __eq__(self, other) -> bool:
        eq = True
        eq = eq and self.bitWidth == other.bitWidth
        eq = eq and self.precision == other.precision
        eq = eq and self.scale == other.scale

        return eq

@dataclass
class Date:
    """ Date is either a 32-bit or 64-bit signed integer type representing an
     elapsed time since UNIX epoch (1970-01-01), stored in either of two units:

     * Milliseconds (64 bits) indicating UNIX time elapsed since the epoch (no
       leap seconds), where the values are evenly divisible by 86400000
     * Days (32 bits) since the UNIX epoch
    """

    unit: "DateUnit"

    @classmethod
    def from_fbs(cls, o: FbsDate) -> Self:
        unit = DateUnit(o.Unit())
        return cls(unit)

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsDate.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Date import (
            Start,
            AddUnit,
            End,
        )
        
        Start(builder)
        AddUnit(builder, self.unit.value)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        unit = DateUnit(0)
        return cls(unit)

    def __eq__(self, other) -> bool:
        eq = True
        eq = eq and self.unit == other.unit

        return eq

@dataclass
class Time:
    """ Time is either a 32-bit or 64-bit signed integer type representing an
     elapsed time since midnight, stored in either of four units: seconds,
     milliseconds, microseconds or nanoseconds.

     The integer `bitWidth` depends on the `unit` and must be one of the following:
     * SECOND and MILLISECOND: 32 bits
     * MICROSECOND and NANOSECOND: 64 bits

     The allowed values are between 0 (inclusive) and 86400 (=24*60*60) seconds
     (exclusive), adjusted for the time unit (for example, up to 86400000
     exclusive for the MILLISECOND unit).
     This definition doesn't allow for leap seconds. Time values from
     measurements with leap seconds will need to be corrected when ingesting
     into Arrow (for example by replacing the value 86400 with 86399).
    """

    bitWidth: "int"

    unit: "TimeUnit"

    @classmethod
    def from_fbs(cls, o: FbsTime) -> Self:
        bitWidth = o.BitWidth()
        unit = TimeUnit(o.Unit())
        return cls(bitWidth, unit)

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsTime.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Time import (
            Start,
            AddBitWidth,
            AddUnit,
            End,
        )
        
        Start(builder)
        AddBitWidth(builder, self.bitWidth)
        AddUnit(builder, self.unit.value)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        bitWidth = 0
        unit = TimeUnit(0)
        return cls(bitWidth, unit)

    def __eq__(self, other) -> bool:
        eq = True
        eq = eq and self.bitWidth == other.bitWidth
        eq = eq and self.unit == other.unit

        return eq

@dataclass
class Timestamp:
    """ Timestamp is a 64-bit signed integer representing an elapsed time since a
     fixed epoch, stored in either of four units: seconds, milliseconds,
     microseconds or nanoseconds, and is optionally annotated with a timezone.

     Timestamp values do not include any leap seconds (in other words, all
     days are considered 86400 seconds long).

     Timestamps with a non-empty timezone
     ------------------------------------

     If a Timestamp column has a non-empty timezone value, its epoch is
     1970-01-01 00:00:00 (January 1st 1970, midnight) in the *UTC* timezone
     (the Unix epoch), regardless of the Timestamp's own timezone.

     Therefore, timestamp values with a non-empty timezone correspond to
     physical points in time together with some additional information about
     how the data was obtained and/or how to display it (the timezone).

       For example, the timestamp value 0 with the timezone string "Europe/Paris"
       corresponds to "January 1st 1970, 00h00" in the UTC timezone, but the
       application may prefer to display it as "January 1st 1970, 01h00" in
       the Europe/Paris timezone (which is the same physical point in time).

     One consequence is that timestamp values with a non-empty timezone
     can be compared and ordered directly, since they all share the same
     well-known point of reference (the Unix epoch).

     Timestamps with an unset / empty timezone
     -----------------------------------------

     If a Timestamp column has no timezone value, its epoch is
     1970-01-01 00:00:00 (January 1st 1970, midnight) in an *unknown* timezone.

     Therefore, timestamp values without a timezone cannot be meaningfully
     interpreted as physical points in time, but only as calendar / clock
     indications ("wall clock time") in an unspecified timezone.

       For example, the timestamp value 0 with an empty timezone string
       corresponds to "January 1st 1970, 00h00" in an unknown timezone: there
       is not enough information to interpret it as a well-defined physical
       point in time.

     One consequence is that timestamp values without a timezone cannot
     be reliably compared or ordered, since they may have different points of
     reference.  In particular, it is *not* possible to interpret an unset
     or empty timezone as the same as "UTC".

     Conversion between timezones
     ----------------------------

     If a Timestamp column has a non-empty timezone, changing the timezone
     to a different non-empty value is a metadata-only operation:
     the timestamp values need not change as their point of reference remains
     the same (the Unix epoch).

     However, if a Timestamp column has no timezone value, changing it to a
     non-empty value requires to think about the desired semantics.
     One possibility is to assume that the original timestamp values are
     relative to the epoch of the timezone being set; timestamp values should
     then adjusted to the Unix epoch (for example, changing the timezone from
     empty to "Europe/Paris" would require converting the timestamp values
     from "Europe/Paris" to "UTC", which seems counter-intuitive but is
     nevertheless correct).

     Guidelines for encoding data from external libraries
     ----------------------------------------------------

     Date & time libraries often have multiple different data types for temporal
     data. In order to ease interoperability between different implementations the
     Arrow project has some recommendations for encoding these types into a Timestamp
     column.

     An "instant" represents a physical point in time that has no relevant timezone
     (for example, astronomical data). To encode an instant, use a Timestamp with
     the timezone string set to "UTC", and make sure the Timestamp values
     are relative to the UTC epoch (January 1st 1970, midnight).

     A "zoned date-time" represents a physical point in time annotated with an
     informative timezone (for example, the timezone in which the data was
     recorded).  To encode a zoned date-time, use a Timestamp with the timezone
     string set to the name of the timezone, and make sure the Timestamp values
     are relative to the UTC epoch (January 1st 1970, midnight).

      (There is some ambiguity between an instant and a zoned date-time with the
       UTC timezone.  Both of these are stored the same in Arrow.  Typically,
       this distinction does not matter.  If it does, then an application should
       use custom metadata or an extension type to distinguish between the two cases.)

     An "offset date-time" represents a physical point in time combined with an
     explicit offset from UTC.  To encode an offset date-time, use a Timestamp
     with the timezone string set to the numeric timezone offset string
     (e.g. "+03:00"), and make sure the Timestamp values are relative to
     the UTC epoch (January 1st 1970, midnight).

     A "naive date-time" (also called "local date-time" in some libraries)
     represents a wall clock time combined with a calendar date, but with
     no indication of how to map this information to a physical point in time.
     Naive date-times must be handled with care because of this missing
     information, and also because daylight saving time (DST) may make
     some values ambiguous or non-existent. A naive date-time may be
     stored as a struct with Date and Time fields. However, it may also be
     encoded into a Timestamp column with an empty timezone. The timestamp
     values should be computed "as if" the timezone of the date-time values
     was UTC; for example, the naive date-time "January 1st 1970, 00h00" would
     be encoded as timestamp value 0.
    """

    # The timezone is an optional string indicating the name of a timezone,
    # one of:
    #
    # * As used in the Olson timezone database (the "tz database" or
    #   "tzdata"), such as "America/New_York".
    # * An absolute timezone offset of the form "+XX:XX" or "-XX:XX",
    #   such as "+07:30".
    #
    # Whether a timezone string is present indicates different semantics about
    # the data (see above).
    timezone: Optional["str"]

    unit: "TimeUnit"

    @classmethod
    def from_fbs(cls, o: FbsTimestamp) -> Self:
        timezone = None
        timezone_str = o.Timezone()
        if timezone_str is not None:
            timezone = timezone_str.decode('utf-8')
        unit = TimeUnit(o.Unit())
        return cls(timezone, unit)

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsTimestamp.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Timestamp import (
            Start,
            AddTimezone,
            AddUnit,
            End,
        )
        timezone_offset = None
        if self.timezone is not None:
            timezone_offset = builder.CreateString(self.timezone)
        
        Start(builder)
        if timezone_offset is not None:
            AddTimezone(builder, timezone_offset)
        AddUnit(builder, self.unit.value)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        timezone = ""
        unit = TimeUnit(0)
        return cls(timezone, unit)

    def __eq__(self, other) -> bool:
        eq = True
        eq = eq and self.timezone == other.timezone
        eq = eq and self.unit == other.unit

        return eq

@dataclass
class Interval:
    unit: "IntervalUnit"

    @classmethod
    def from_fbs(cls, o: FbsInterval) -> Self:
        unit = IntervalUnit(o.Unit())
        return cls(unit)

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsInterval.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Interval import (
            Start,
            AddUnit,
            End,
        )
        
        Start(builder)
        AddUnit(builder, self.unit.value)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        unit = IntervalUnit(0)
        return cls(unit)

    def __eq__(self, other) -> bool:
        eq = True
        eq = eq and self.unit == other.unit

        return eq

@dataclass
class List_:
    @classmethod
    def from_fbs(cls, o: FbsList) -> Self:
        return cls()

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsList.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.List import (
            Start,
            End,
        )
        
        Start(builder)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        return cls()

    def __eq__(self, other) -> bool:
        eq = True

        return eq

@dataclass
class Struct_:
    """ A Struct_ in the flatbuffer metadata is the same as an Arrow Struct
     (according to the physical memory layout). We used Struct_ here as
     Struct is a reserved word in Flatbuffers
    """

    @classmethod
    def from_fbs(cls, o: FbsStruct_) -> Self:
        return cls()

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsStruct_.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Struct_ import (
            Start,
            End,
        )
        
        Start(builder)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        return cls()

    def __eq__(self, other) -> bool:
        eq = True

        return eq

@dataclass
class Union_:
    """ A union is a complex type with children in Field
     By default ids in the type vector refer to the offsets in the children
     optionally typeIds provides an indirection between the child offset and the type id
     for each child `typeIds[offset]` is the id used in the type vector
    """

    mode: "UnionMode"

    typeIds: Optional["List[int]"]

    @classmethod
    def from_fbs(cls, o: FbsUnion) -> Self:
        mode = UnionMode(o.Mode())
        typeIds = list()
        if not o.TypeIdsIsNone():
            for i in range(o.TypeIdsLength()):
                typeIds.append(o.TypeIds(i))
        return cls(mode, typeIds)

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsUnion.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Union import (
            Start,
            AddMode,
            AddTypeIds,
            StartTypeIdsVector,
            End,
        )
        typeIds_offset = None
        if self.typeIds is not None:
            StartTypeIdsVector(builder, len(self.typeIds))
            for i in reversed(range(len(self.typeIds))):
                builder.PrependInt32(self.typeIds[i])
            typeIds_offset = builder.EndVector()
        
        Start(builder)
        AddMode(builder, self.mode.value)
        if typeIds_offset is not None:
            AddTypeIds(builder, typeIds_offset)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        mode = UnionMode(0)
        typeIds = []
        return cls(mode, typeIds)

    def __eq__(self, other) -> bool:
        eq = True
        eq = eq and self.mode == other.mode
        self_typeIds = self.typeIds
        other_typeIds = other.typeIds
        if self_typeIds is not None and other_typeIds is not None:
            if len(self_typeIds) != len(other_typeIds):
                return False
            for i in range(len(self_typeIds)):
                eq = eq and self_typeIds[i] == other_typeIds[i]
        elif self_typeIds is not None and other_typeIds is None:
            return False
        elif self_typeIds is None and other_typeIds is not None:
            return False

        return eq

@dataclass
class FixedSizeBinary:
    # Number of bytes per value
    byteWidth: "int"

    @classmethod
    def from_fbs(cls, o: FbsFixedSizeBinary) -> Self:
        byteWidth = o.ByteWidth()
        return cls(byteWidth)

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsFixedSizeBinary.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.FixedSizeBinary import (
            Start,
            AddByteWidth,
            End,
        )
        
        Start(builder)
        AddByteWidth(builder, self.byteWidth)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        byteWidth = 0
        return cls(byteWidth)

    def __eq__(self, other) -> bool:
        eq = True
        eq = eq and self.byteWidth == other.byteWidth

        return eq

@dataclass
class FixedSizeList:
    # Number of list items per value
    listSize: "int"

    @classmethod
    def from_fbs(cls, o: FbsFixedSizeList) -> Self:
        listSize = o.ListSize()
        return cls(listSize)

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsFixedSizeList.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.FixedSizeList import (
            Start,
            AddListSize,
            End,
        )
        
        Start(builder)
        AddListSize(builder, self.listSize)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        listSize = 0
        return cls(listSize)

    def __eq__(self, other) -> bool:
        eq = True
        eq = eq and self.listSize == other.listSize

        return eq

@dataclass
class Map:
    """ A Map is a logical nested type that is represented as

     List<entries: Struct<key: K, value: V>>

     In this layout, the keys and values are each respectively contiguous. We do
     not constrain the key and value types, so the application is responsible
     for ensuring that the keys are hashable and unique. Whether the keys are sorted
     may be set in the metadata for this field.

     In a field with Map type, the field has a child Struct field, which then
     has two children: key type and the second the value type. The names of the
     child fields may be respectively "entries", "key", and "value", but this is
     not enforced.

     Map
     ```text
       - child[0] entries: Struct
         - child[0] key: K
         - child[1] value: V
     ```
     Neither the "entries" field nor the "key" field may be nullable.

     The metadata is structured so that Arrow systems without special handling
     for Map can make Map an alias for List. The "layout" attribute for the Map
     field must have the same contents as a List.
    """

    # Set to true if the keys within each value are sorted
    keysSorted: "bool"

    @classmethod
    def from_fbs(cls, o: FbsMap) -> Self:
        keysSorted = o.KeysSorted()
        return cls(keysSorted)

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsMap.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Map import (
            Start,
            AddKeysSorted,
            End,
        )
        
        Start(builder)
        AddKeysSorted(builder, self.keysSorted)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        keysSorted = False
        return cls(keysSorted)

    def __eq__(self, other) -> bool:
        eq = True
        eq = eq and self.keysSorted == other.keysSorted

        return eq

@dataclass
class Duration:
    unit: "TimeUnit"

    @classmethod
    def from_fbs(cls, o: FbsDuration) -> Self:
        unit = TimeUnit(o.Unit())
        return cls(unit)

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsDuration.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Duration import (
            Start,
            AddUnit,
            End,
        )
        
        Start(builder)
        AddUnit(builder, self.unit.value)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        unit = TimeUnit(0)
        return cls(unit)

    def __eq__(self, other) -> bool:
        eq = True
        eq = eq and self.unit == other.unit

        return eq

@dataclass
class LargeBinary:
    """ Same as Binary, but with 64-bit offsets, allowing to represent
     extremely large data values.
    """

    @classmethod
    def from_fbs(cls, o: FbsLargeBinary) -> Self:
        return cls()

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsLargeBinary.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.LargeBinary import (
            Start,
            End,
        )
        
        Start(builder)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        return cls()

    def __eq__(self, other) -> bool:
        eq = True

        return eq

@dataclass
class LargeUtf8:
    """ Same as Utf8, but with 64-bit offsets, allowing to represent
     extremely large data values.
    """

    @classmethod
    def from_fbs(cls, o: FbsLargeUtf8) -> Self:
        return cls()

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsLargeUtf8.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.LargeUtf8 import (
            Start,
            End,
        )
        
        Start(builder)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        return cls()

    def __eq__(self, other) -> bool:
        eq = True

        return eq

@dataclass
class LargeList:
    """ Same as List, but with 64-bit offsets, allowing to represent
     extremely large data values.
    """

    @classmethod
    def from_fbs(cls, o: FbsLargeList) -> Self:
        return cls()

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsLargeList.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.LargeList import (
            Start,
            End,
        )
        
        Start(builder)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        return cls()

    def __eq__(self, other) -> bool:
        eq = True

        return eq

@dataclass
class Type:
    """ ----------------------------------------------------------------------
     Top-level Type value, enabling extensible type-specific metadata. We can
     add new logical types to Type without breaking backwards compatibility
"""

    value: Union[
        "Null",
        "Int",
        "FloatingPoint",
        "Binary",
        "Utf8",
        "Bool",
        "Decimal",
        "Date",
        "Time",
        "Timestamp",
        "Interval",
        "List_",
        "Struct_",
        "Union_",
        "FixedSizeBinary",
        "FixedSizeList",
        "Map",
        "Duration",
        "LargeBinary",
        "LargeUtf8",
        "LargeList",
    ]

    def serialize_to(self, builder: Builder) -> Tuple[int, int]:
        from .generated.Type import Type
        offset = self.value.serialize_to(builder)
        if isinstance(self.value, Null):
            return (offset, Type().Null)
        elif isinstance(self.value, Int):
            return (offset, Type().Int)
        elif isinstance(self.value, FloatingPoint):
            return (offset, Type().FloatingPoint)
        elif isinstance(self.value, Binary):
            return (offset, Type().Binary)
        elif isinstance(self.value, Utf8):
            return (offset, Type().Utf8)
        elif isinstance(self.value, Bool):
            return (offset, Type().Bool)
        elif isinstance(self.value, Decimal):
            return (offset, Type().Decimal)
        elif isinstance(self.value, Date):
            return (offset, Type().Date)
        elif isinstance(self.value, Time):
            return (offset, Type().Time)
        elif isinstance(self.value, Timestamp):
            return (offset, Type().Timestamp)
        elif isinstance(self.value, Interval):
            return (offset, Type().Interval)
        elif isinstance(self.value, List_):
            return (offset, Type().List)
        elif isinstance(self.value, Struct_):
            return (offset, Type().Struct_)
        elif isinstance(self.value, Union_):
            return (offset, Type().Union)
        elif isinstance(self.value, FixedSizeBinary):
            return (offset, Type().FixedSizeBinary)
        elif isinstance(self.value, FixedSizeList):
            return (offset, Type().FixedSizeList)
        elif isinstance(self.value, Map):
            return (offset, Type().Map)
        elif isinstance(self.value, Duration):
            return (offset, Type().Duration)
        elif isinstance(self.value, LargeBinary):
            return (offset, Type().LargeBinary)
        elif isinstance(self.value, LargeUtf8):
            return (offset, Type().LargeUtf8)
        elif isinstance(self.value, LargeList):
            return (offset, Type().LargeList)
        raise ValueError("Invalid union type")

    @classmethod
    def from_fbs(cls, o: Optional[Table], ty: int) -> Self:
        assert o is not None
        source = o.Bytes
        pos = o.Pos
        Type_ty_instance = FbsType()
        if ty == Type_ty_instance.Null:
            val = FbsNull();
            val.Init(source, pos)
            return cls(Null.from_fbs(val))
        elif ty == Type_ty_instance.Int:
            val = FbsInt();
            val.Init(source, pos)
            return cls(Int.from_fbs(val))
        elif ty == Type_ty_instance.FloatingPoint:
            val = FbsFloatingPoint();
            val.Init(source, pos)
            return cls(FloatingPoint.from_fbs(val))
        elif ty == Type_ty_instance.Binary:
            val = FbsBinary();
            val.Init(source, pos)
            return cls(Binary.from_fbs(val))
        elif ty == Type_ty_instance.Utf8:
            val = FbsUtf8();
            val.Init(source, pos)
            return cls(Utf8.from_fbs(val))
        elif ty == Type_ty_instance.Bool:
            val = FbsBool();
            val.Init(source, pos)
            return cls(Bool.from_fbs(val))
        elif ty == Type_ty_instance.Decimal:
            val = FbsDecimal();
            val.Init(source, pos)
            return cls(Decimal.from_fbs(val))
        elif ty == Type_ty_instance.Date:
            val = FbsDate();
            val.Init(source, pos)
            return cls(Date.from_fbs(val))
        elif ty == Type_ty_instance.Time:
            val = FbsTime();
            val.Init(source, pos)
            return cls(Time.from_fbs(val))
        elif ty == Type_ty_instance.Timestamp:
            val = FbsTimestamp();
            val.Init(source, pos)
            return cls(Timestamp.from_fbs(val))
        elif ty == Type_ty_instance.Interval:
            val = FbsInterval();
            val.Init(source, pos)
            return cls(Interval.from_fbs(val))
        elif ty == Type_ty_instance.List:
            val = FbsList();
            val.Init(source, pos)
            return cls(List_.from_fbs(val))
        elif ty == Type_ty_instance.Struct_:
            val = FbsStruct_();
            val.Init(source, pos)
            return cls(Struct_.from_fbs(val))
        elif ty == Type_ty_instance.Union:
            val = FbsUnion();
            val.Init(source, pos)
            return cls(Union_.from_fbs(val))
        elif ty == Type_ty_instance.FixedSizeBinary:
            val = FbsFixedSizeBinary();
            val.Init(source, pos)
            return cls(FixedSizeBinary.from_fbs(val))
        elif ty == Type_ty_instance.FixedSizeList:
            val = FbsFixedSizeList();
            val.Init(source, pos)
            return cls(FixedSizeList.from_fbs(val))
        elif ty == Type_ty_instance.Map:
            val = FbsMap();
            val.Init(source, pos)
            return cls(Map.from_fbs(val))
        elif ty == Type_ty_instance.Duration:
            val = FbsDuration();
            val.Init(source, pos)
            return cls(Duration.from_fbs(val))
        elif ty == Type_ty_instance.LargeBinary:
            val = FbsLargeBinary();
            val.Init(source, pos)
            return cls(LargeBinary.from_fbs(val))
        elif ty == Type_ty_instance.LargeUtf8:
            val = FbsLargeUtf8();
            val.Init(source, pos)
            return cls(LargeUtf8.from_fbs(val))
        elif ty == Type_ty_instance.LargeList:
            val = FbsLargeList();
            val.Init(source, pos)
            return cls(LargeList.from_fbs(val))
        else:
            raise ValueError("Invalid union type")

    @classmethod
    def make_default(cls) -> Self:
        return cls(Null.make_default())

    def __eq__(self, other) -> bool:
        if type(self.value) is not type(other.value):
            return False
        return self.value == other.value

@dataclass
class Buffer:
    """ ----------------------------------------------------------------------
     A Buffer represents a single contiguous memory segment
    """

    # The absolute length (in bytes) of the memory buffer. The memory is found
    # from offset (inclusive) to offset + length (non-inclusive). When building
    # messages using the encapsulated IPC message, padding bytes may be written
    # after a buffer, but such padding bytes do not need to be accounted for in
    # the size here.
    length: "int"

    # The relative offset into the shared memory page where the bytes for this
    # buffer starts
    offset: "int"

    @classmethod
    def from_fbs(cls, o: FbsBuffer) -> Self:
        length = o.Length()
        offset = o.Offset()
        return cls(length, offset)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Buffer import CreateBuffer
        length = self.length
        offset = self.offset
        return CreateBuffer(builder, length, offset)

    @classmethod
    def make_default(cls) -> Self:
        length = 0
        offset = 0
        return cls(length, offset)

    def __eq__(self, other) -> bool:
        eq = True
        eq = eq and self.length == other.length
        eq = eq and self.offset == other.offset

        return eq

@dataclass
class DictionaryEncoding:
    dictionaryKind: "DictionaryKind"

    # The known dictionary id in the application where this data is used. In
    # the file or streaming formats, the dictionary ids are found in the
    # DictionaryBatch messages
    id: "int"

    # The dictionary indices are constrained to be non-negative integers. If
    # this field is null, the indices must be signed int32. To maximize
    # cross-language compatibility and performance, implementations are
    # recommended to prefer signed integer types over unsigned integer types
    # and to avoid uint64 indices unless they are required by an application.
    indexType: Optional["Int"]

    # By default, dictionaries are not ordered, or the order does not have
    # semantic meaning. In some statistical, applications, dictionary-encoding
    # is used to represent ordered categorical data, and we provide a way to
    # preserve that metadata here
    isOrdered: "bool"

    @classmethod
    def from_fbs(cls, o: FbsDictionaryEncoding) -> Self:
        dictionaryKind = DictionaryKind(o.DictionaryKind())
        id = o.Id()
        indexType = None
        indexType_obj = o.IndexType()
        if indexType_obj is not None:
            indexType = Int.from_fbs(indexType_obj)
        isOrdered = o.IsOrdered()
        return cls(dictionaryKind, id, indexType, isOrdered)

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsDictionaryEncoding.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.DictionaryEncoding import (
            Start,
            AddDictionaryKind,
            AddId,
            AddIndexType,
            AddIsOrdered,
            End,
        )
        indexType_offset = None
        if self.indexType is not None:
            indexType_offset = self.indexType.serialize_to(builder)
        
        Start(builder)
        AddDictionaryKind(builder, self.dictionaryKind.value)
        AddId(builder, self.id)
        if indexType_offset is not None:
            AddIndexType(builder, indexType_offset)
        AddIsOrdered(builder, self.isOrdered)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        dictionaryKind = DictionaryKind(0)
        id = 0
        indexType = Int.make_default()
        isOrdered = False
        return cls(dictionaryKind, id, indexType, isOrdered)

    def __eq__(self, other) -> bool:
        eq = True
        eq = eq and self.dictionaryKind == other.dictionaryKind
        eq = eq and self.id == other.id
        eq = eq and self.indexType == other.indexType
        eq = eq and self.isOrdered == other.isOrdered

        return eq

@dataclass
class Field:
    """ ----------------------------------------------------------------------
     A field represents a named column in a record / row batch or child of a
     nested type.
    """

    # children apply only to nested data types like Struct, List and Union. For
    # primitive types children will have length 0.
    children: Optional["List[Field]"]

    # User-defined metadata
    custom_metadata: Optional["List[KeyValue]"]

    # Present only if the field is dictionary encoded.
    dictionary: Optional["DictionaryEncoding"]

    # Name is not required, in i.e. a List
    name: Optional["str"]

    # Whether or not this field can contain nulls. Should be true in general.
    nullable: "bool"

    # This is the type of the decoded value if the field is dictionary encoded.
    type: Optional["Type"]

    @classmethod
    def from_fbs(cls, o: FbsField) -> Self:
        children = list()
        if not o.ChildrenIsNone():
            for i in range(o.ChildrenLength()):
                children_val = None
                children_obj = o.Children(i)
                if children_obj is not None:
                    children_val = Field.from_fbs(children_obj)
                children.append(children_val)
        custom_metadata = list()
        if not o.CustomMetadataIsNone():
            for i in range(o.CustomMetadataLength()):
                custom_metadata_val = None
                custom_metadata_obj = o.CustomMetadata(i)
                if custom_metadata_obj is not None:
                    custom_metadata_val = KeyValue.from_fbs(custom_metadata_obj)
                custom_metadata.append(custom_metadata_val)
        dictionary = None
        dictionary_obj = o.Dictionary()
        if dictionary_obj is not None:
            dictionary = DictionaryEncoding.from_fbs(dictionary_obj)
        name = None
        name_str = o.Name()
        if name_str is not None:
            name = name_str.decode('utf-8')
        nullable = o.Nullable()
        type = None
        type_val = o.Type()
        if type_val is not None:
            type_ty = o.TypeType()
            type = Type.from_fbs(type_val, type_ty)
        return cls(children, custom_metadata, dictionary, name, nullable, type)

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsField.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Field import (
            Start,
            AddChildren,
            StartChildrenVector,
            AddCustomMetadata,
            StartCustomMetadataVector,
            AddDictionary,
            AddName,
            AddNullable,
            AddType,
            AddTypeType,
            End,
        )
        children_offset = None
        if self.children is not None:
            children_offsets = list()
            for value in self.children:
                children_offsets.append(value.serialize_to(builder))
            StartChildrenVector(builder, len(self.children))
            for i in reversed(range(len(self.children))):
                builder.PrependUOffsetTRelative(children_offsets[i])
            children_offset = builder.EndVector()
        custom_metadata_offset = None
        if self.custom_metadata is not None:
            custom_metadata_offsets = list()
            for value in self.custom_metadata:
                custom_metadata_offsets.append(value.serialize_to(builder))
            StartCustomMetadataVector(builder, len(self.custom_metadata))
            for i in reversed(range(len(self.custom_metadata))):
                builder.PrependUOffsetTRelative(custom_metadata_offsets[i])
            custom_metadata_offset = builder.EndVector()
        dictionary_offset = None
        if self.dictionary is not None:
            dictionary_offset = self.dictionary.serialize_to(builder)
        name_offset = None
        if self.name is not None:
            name_offset = builder.CreateString(self.name)
        type_offset, type_ty = (None, None)
        if self.type is not None:
            type_offset, type_ty = self.type.serialize_to(builder)
        
        Start(builder)
        if children_offset is not None:
            AddChildren(builder, children_offset)
        if custom_metadata_offset is not None:
            AddCustomMetadata(builder, custom_metadata_offset)
        if dictionary_offset is not None:
            AddDictionary(builder, dictionary_offset)
        if name_offset is not None:
            AddName(builder, name_offset)
        AddNullable(builder, self.nullable)
        if type_offset is not None and type_ty is not None:
            AddType(builder, type_offset)
            AddTypeType(builder, type_ty)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        children = []
        custom_metadata = []
        dictionary = DictionaryEncoding.make_default()
        name = ""
        nullable = False
        type = Type.make_default()
        return cls(children, custom_metadata, dictionary, name, nullable, type)

    def __eq__(self, other) -> bool:
        eq = True
        self_children = self.children
        other_children = other.children
        if self_children is not None and other_children is not None:
            if len(self_children) != len(other_children):
                return False
            for i in range(len(self_children)):
                eq = eq and self_children[i] == other_children[i]
        elif self_children is not None and other_children is None:
            return False
        elif self_children is None and other_children is not None:
            return False
        self_custom_metadata = self.custom_metadata
        other_custom_metadata = other.custom_metadata
        if self_custom_metadata is not None and other_custom_metadata is not None:
            if len(self_custom_metadata) != len(other_custom_metadata):
                return False
            for i in range(len(self_custom_metadata)):
                eq = eq and self_custom_metadata[i] == other_custom_metadata[i]
        elif self_custom_metadata is not None and other_custom_metadata is None:
            return False
        elif self_custom_metadata is None and other_custom_metadata is not None:
            return False
        eq = eq and self.dictionary == other.dictionary
        eq = eq and self.name == other.name
        eq = eq and self.nullable == other.nullable
        eq = eq and self.type == other.type

        return eq

@dataclass
class KeyValue:
    """ ----------------------------------------------------------------------
     user defined key value pairs to add custom metadata to arrow
     key namespacing is the responsibility of the user
    """

    key: Optional["str"]

    value: Optional["str"]

    @classmethod
    def from_fbs(cls, o: FbsKeyValue) -> Self:
        key = None
        key_str = o.Key()
        if key_str is not None:
            key = key_str.decode('utf-8')
        value = None
        value_str = o.Value()
        if value_str is not None:
            value = value_str.decode('utf-8')
        return cls(key, value)

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsKeyValue.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.KeyValue import (
            Start,
            AddKey,
            AddValue,
            End,
        )
        key_offset = None
        if self.key is not None:
            key_offset = builder.CreateString(self.key)
        value_offset = None
        if self.value is not None:
            value_offset = builder.CreateString(self.value)
        
        Start(builder)
        if key_offset is not None:
            AddKey(builder, key_offset)
        if value_offset is not None:
            AddValue(builder, value_offset)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        key = ""
        value = ""
        return cls(key, value)

    def __eq__(self, other) -> bool:
        eq = True
        eq = eq and self.key == other.key
        eq = eq and self.value == other.value

        return eq

@dataclass
class Schema:
    """ ----------------------------------------------------------------------
     A Schema describes the columns in a row batch
    """

    custom_metadata: Optional["List[KeyValue]"]

    # endianness of the buffer
    # it is Little Endian by default
    # if endianness doesn't match the underlying system then the vectors need to be converted
    endianness: "Endianness"

    # Features used in the stream/file.
    features: Optional["List[Feature]"]

    fields: Optional["List[Field]"]

    @classmethod
    def from_fbs(cls, o: FbsSchema) -> Self:
        custom_metadata = list()
        if not o.CustomMetadataIsNone():
            for i in range(o.CustomMetadataLength()):
                custom_metadata_val = None
                custom_metadata_obj = o.CustomMetadata(i)
                if custom_metadata_obj is not None:
                    custom_metadata_val = KeyValue.from_fbs(custom_metadata_obj)
                custom_metadata.append(custom_metadata_val)
        endianness = Endianness(o.Endianness())
        features = list()
        if not o.FeaturesIsNone():
            for i in range(o.FeaturesLength()):
                features.append(o.Features(i))
        fields = list()
        if not o.FieldsIsNone():
            for i in range(o.FieldsLength()):
                fields_val = None
                fields_obj = o.Fields(i)
                if fields_obj is not None:
                    fields_val = Field.from_fbs(fields_obj)
                fields.append(fields_val)
        return cls(custom_metadata, endianness, features, fields)

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsSchema.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Schema import (
            Start,
            AddCustomMetadata,
            StartCustomMetadataVector,
            AddEndianness,
            AddFeatures,
            StartFeaturesVector,
            AddFields,
            StartFieldsVector,
            End,
        )
        custom_metadata_offset = None
        if self.custom_metadata is not None:
            custom_metadata_offsets = list()
            for value in self.custom_metadata:
                custom_metadata_offsets.append(value.serialize_to(builder))
            StartCustomMetadataVector(builder, len(self.custom_metadata))
            for i in reversed(range(len(self.custom_metadata))):
                builder.PrependUOffsetTRelative(custom_metadata_offsets[i])
            custom_metadata_offset = builder.EndVector()
        features_offset = None
        if self.features is not None:
            StartFeaturesVector(builder, len(self.features))
            for i in reversed(range(len(self.features))):
                builder.PrependInt64(self.features[i])
            features_offset = builder.EndVector()
        fields_offset = None
        if self.fields is not None:
            fields_offsets = list()
            for value in self.fields:
                fields_offsets.append(value.serialize_to(builder))
            StartFieldsVector(builder, len(self.fields))
            for i in reversed(range(len(self.fields))):
                builder.PrependUOffsetTRelative(fields_offsets[i])
            fields_offset = builder.EndVector()
        
        Start(builder)
        if custom_metadata_offset is not None:
            AddCustomMetadata(builder, custom_metadata_offset)
        AddEndianness(builder, self.endianness.value)
        if features_offset is not None:
            AddFeatures(builder, features_offset)
        if fields_offset is not None:
            AddFields(builder, fields_offset)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        custom_metadata = []
        endianness = Endianness(0)
        features = []
        fields = []
        return cls(custom_metadata, endianness, features, fields)

    def __eq__(self, other) -> bool:
        eq = True
        self_custom_metadata = self.custom_metadata
        other_custom_metadata = other.custom_metadata
        if self_custom_metadata is not None and other_custom_metadata is not None:
            if len(self_custom_metadata) != len(other_custom_metadata):
                return False
            for i in range(len(self_custom_metadata)):
                eq = eq and self_custom_metadata[i] == other_custom_metadata[i]
        elif self_custom_metadata is not None and other_custom_metadata is None:
            return False
        elif self_custom_metadata is None and other_custom_metadata is not None:
            return False
        eq = eq and self.endianness == other.endianness
        self_features = self.features
        other_features = other.features
        if self_features is not None and other_features is not None:
            if len(self_features) != len(other_features):
                return False
            for i in range(len(self_features)):
                eq = eq and self_features[i] == other_features[i]
        elif self_features is not None and other_features is None:
            return False
        elif self_features is None and other_features is not None:
            return False
        self_fields = self.fields
        other_fields = other.fields
        if self_fields is not None and other_fields is not None:
            if len(self_fields) != len(other_fields):
                return False
            for i in range(len(self_fields)):
                eq = eq and self_fields[i] == other_fields[i]
        elif self_fields is not None and other_fields is None:
            return False
        elif self_fields is None and other_fields is not None:
            return False

        return eq
