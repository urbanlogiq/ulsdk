# Copyright (c), CommunityLogiq Software
# 
# THIS FILE IS AUTOGENERATED, DO NOT EDIT

from dataclasses import dataclass
import json
from pyarrow import RecordBatch, BufferOutputStream, RecordBatchStreamWriter, RecordBatchStreamReader
from typing import Optional, Any, List, Dict, Self
from urllib.parse import quote_plus
from uuid import UUID
from ..request_context import RequestContext
from ..types.id import ObjectId
from ..types.metadata import Metadata
from ..types.object import (
    DataCatalogObject,
    ObjectIdList,
    ObjectIdPairList,
    ObjectSummary,
    ObjectSummaryList,
)
from ..types.query import Query
from ..types.table import DiffStream, History, NewTable

def get_object_at_revision(
    ctx: RequestContext,
    object_id: UUID,
    content_id: UUID,
) -> DataCatalogObject:
    """Fetch an object at a given content ID revision

    Arguments:
    ctx: RequestContext -- A request context object
    object_id: UUID -- The ID of the object to fetch content from
    content_id: UUID -- The ID of the content to fetch

    Returns:
    The datacatalog object
    """

    path = "/v1/api/ulv2/datacatalog/content/:object_id/:content_id"
    path.replace(":object_id", str(object_id), 1)
    path.replace(":content_id", str(content_id), 1)

    params = dict()
    headers = dict()
    res = ctx.get(path, params=params, headers=headers)
    return DataCatalogObject.from_bytes(res)

def get_acl(
    ctx: RequestContext,
    id_: UUID,
) -> ObjectId:
    """Fetch the ID of the ACL object associated with the given object ID

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the object to fetch the ACL for

    Returns:
    The ID of the object's ACL
    """

    path = "/v1/api/ulv2/datacatalog/object/acl/:id"
    path.replace(":id", str(id_), 1)

    params = dict()
    headers = dict()
    res = ctx.get(path, params=params, headers=headers)
    return ObjectId.from_bytes(res)

def get_head_revision(
    ctx: RequestContext,
    id_: UUID,
) -> ObjectSummary:
    """Fetch the head revision of the object with the given ID

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the object to fetch the head revision for

    Returns:
    The summary for the head revision of the object
    """

    path = "/v1/api/ulv2/datacatalog/object/head/:id"
    path.replace(":id", str(id_), 1)

    params = dict()
    headers = dict()
    res = ctx.get(path, params=params, headers=headers)
    return ObjectSummary.from_bytes(res)

def get_object(
    ctx: RequestContext,
    id_: UUID,
) -> DataCatalogObject:
    """Fetch the object with the given ID at its head revision

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the object to fetch

    Returns:
    Object content
    """

    path = "/v1/api/ulv2/datacatalog/object/:id"
    path.replace(":id", str(id_), 1)

    params = dict()
    headers = dict()
    res = ctx.get(path, params=params, headers=headers)
    return DataCatalogObject.from_bytes(res)

def update_object(
    ctx: RequestContext,
    id_: UUID,
    object: DataCatalogObject,
) -> None:
    """Update the object with the given ID

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the object to update
    object: DataCatalogObject -- Object contents with which to update the specified object
    """

    path = "/v1/api/ulv2/datacatalog/object/:id"
    path.replace(":id", str(id_), 1)

    params = dict()
    headers = dict()
    body = object.to_bytes()
    ctx.post(path, body=body, mimetype="application/octet-stream", params=params, headers=headers)
    return

def update_attribute(
    ctx: RequestContext,
    id_: UUID,
    overwrite: bool,
    attributes: Dict[str, Any],
) -> None:
    """Update the attributes of the object with the given ID

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the object whose attributes will be updated
    overwrite: bool -- True to overwrite existing attributes or false to fail if there is a conflict.
    attributes: Dict[str, Any] -- A string:string json map with the new attributes
    """

    path = "/v1/api/ulv2/datacatalog/object/:id/attributes"
    path.replace(":id", str(id_), 1)

    params = dict()
    params["overwrite"] = "true" if overwrite else "false"

    headers = dict()
    body = json.dumps(attributes)
    ctx.post(path, body=body, mimetype="application/json", params=params, headers=headers)
    return

def delete_attribute(
    ctx: RequestContext,
    id_: UUID,
    key: str,
) -> None:
    """Delete the attribute with the given key from the object with the given ID

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the object whose attribute will be deleted
    key: str -- The key of the attribute to delete
    """

    path = "/v1/api/ulv2/datacatalog/object/:id/attributes/:key"
    path.replace(":id", str(id_), 1)
    path.replace(":key", str(key), 1)

    params = dict()
    headers = dict()
    ctx.delete(path, params=params, headers=headers)
    return

def get_object_summaries(
    ctx: RequestContext,
    object_ids: ObjectIdList,
) -> ObjectSummaryList:
    """Fetch a list of object summaries

    Arguments:
    ctx: RequestContext -- A request context object
    object_ids: ObjectIdList -- A list of object IDs to fetch summaries for

    Returns:
    A list of object summaries
    """

    path = "/v1/api/ulv2/datacatalog/object_summaries"
    params = dict()
    headers = dict()
    body = object_ids.to_bytes()
    res = ctx.post(path, body=body, mimetype="application/octet-stream", params=params, headers=headers)
    return ObjectSummaryList.from_bytes(res)

def bulk_fetch_objects(
    ctx: RequestContext,
    object_ids: ObjectIdList,
) -> ObjectIdPairList:
    """Given a list of object IDs, fetch their contents in bulk

    Arguments:
    ctx: RequestContext -- A request context object
    object_ids: ObjectIdList -- A list of object IDs to fetch summaries for

    Returns:
    A list of object contents with their IDs
    """

    path = "/v1/api/ulv2/datacatalog/object_list"
    params = dict()
    headers = dict()
    body = object_ids.to_bytes()
    res = ctx.post(path, body=body, mimetype="application/octet-stream", params=params, headers=headers)
    return ObjectIdPairList.from_bytes(res)

def create_object(
    ctx: RequestContext,
) -> ObjectSummaryList:
    """Create a new, empty object

    Arguments:
    ctx: RequestContext -- A request context object

    Returns:
    The object summary of the newly created object
    """

    path = "/v1/api/ulv2/datacatalog/objects"
    params = dict()
    headers = dict()
    body = None
    res = ctx.post(path, body=body, mimetype="text/plain", params=params, headers=headers)
    return ObjectSummaryList.from_bytes(res)

def query_aggregate_numeric(
    ctx: RequestContext,
    columns: str,
    query: Query,
) -> List[RecordBatch]:
    """INTERNAL

    Arguments:
    ctx: RequestContext -- A request context object
    columns: str -- Comma separated list of columns to aggregate
    query: Query -- INTERNAL

    Returns:
    INTERNAL
    """

    path = "/v1/api/ulv2/datacatalog/query/aggregate/numeric"
    params = dict()
    params["columns"] = columns

    headers = dict()
    body = query.to_bytes()
    res = ctx.post(path, body=body, mimetype="application/octet-stream", params=params, headers=headers)
    reader = RecordBatchStreamReader(res)
    return reader.read_all().to_batches()

def query_aggregate_string(
    ctx: RequestContext,
    columns: str,
    query: Query,
) -> List[RecordBatch]:
    """INTERNAL

    Arguments:
    ctx: RequestContext -- A request context object
    columns: str -- Comma separated list of columns to aggregate
    query: Query -- INTERNAL

    Returns:
    INTERNAL
    """

    path = "/v1/api/ulv2/datacatalog/query/aggregate/string"
    params = dict()
    params["columns"] = columns

    headers = dict()
    body = query.to_bytes()
    res = ctx.post(path, body=body, mimetype="application/octet-stream", params=params, headers=headers)
    reader = RecordBatchStreamReader(res)
    return reader.read_all().to_batches()

def query_aggregate_histo(
    ctx: RequestContext,
    buckets: int,
    columns: str,
    query: Query,
) -> List[RecordBatch]:
    """INTERNAL

    Arguments:
    ctx: RequestContext -- A request context object
    buckets: int -- Number of buckets
    columns: str -- Comma separated list of columns to aggregate
    query: Query -- INTERNAL

    Returns:
    INTERNAL
    """

    path = "/v1/api/ulv2/datacatalog/query/aggregate/histo"
    params = dict()
    params["buckets"] = str(buckets)
    params["columns"] = columns

    headers = dict()
    body = query.to_bytes()
    res = ctx.post(path, body=body, mimetype="application/octet-stream", params=params, headers=headers)
    reader = RecordBatchStreamReader(res)
    return reader.read_all().to_batches()

def query_aggregate_relative_histo(
    ctx: RequestContext,
    buckets: int,
    numerator_columns: str,
    denominator_columns: str,
    query: Query,
) -> List[RecordBatch]:
    """INTERNAL

    Arguments:
    ctx: RequestContext -- A request context object
    buckets: int -- Number of buckets
    numerator_columns: str -- Comma separated list of columns to aggregate for the numerator value
    denominator_columns: str -- Comma separated list of columns to aggregate for the denominator value
    query: Query -- INTERNAL

    Returns:
    INTERNAL
    """

    path = "/v1/api/ulv2/datacatalog/query/aggregate/relative_histo"
    params = dict()
    params["buckets"] = str(buckets)
    params["numerator_columns"] = numerator_columns
    params["denominator_columns"] = denominator_columns

    headers = dict()
    body = query.to_bytes()
    res = ctx.post(path, body=body, mimetype="application/octet-stream", params=params, headers=headers)
    reader = RecordBatchStreamReader(res)
    return reader.read_all().to_batches()

def stream_get_arrow(
    ctx: RequestContext,
    id_: UUID,
) -> List[RecordBatch]:
    """Fetch the stream with the given ID

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the stream to fetch

    Returns:
    Stream data as requested
    """

    path = "/v1/api/ulv2/datacatalog/stream/:id"
    path.replace(":id", str(id_), 1)

    params = dict()
    headers = dict()
    headers["Accept"] = "application/vnd.apache.arrow.stream";

    res = ctx.get(path, params=params, headers=headers)
    reader = RecordBatchStreamReader(res)
    return reader.read_all().to_batches()

def stream_get_parquet(
    ctx: RequestContext,
    id_: UUID,
) -> bytes:
    """Fetch the stream with the given ID

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the stream to fetch

    Returns:
    Stream data as requested
    """

    path = "/v1/api/ulv2/datacatalog/stream/:id"
    path.replace(":id", str(id_), 1)

    params = dict()
    headers = dict()
    headers["Accept"] = "application/vnd.apache.parquet";

    res = ctx.get(path, params=params, headers=headers)
    return res

def stream_get_csv(
    ctx: RequestContext,
    id_: UUID,
) -> bytes:
    """Fetch the stream with the given ID

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the stream to fetch

    Returns:
    Stream data as requested
    """

    path = "/v1/api/ulv2/datacatalog/stream/:id"
    path.replace(":id", str(id_), 1)

    params = dict()
    headers = dict()
    headers["Accept"] = "text/csv";

    res = ctx.get(path, params=params, headers=headers)
    return res

def stream_get_xlsx(
    ctx: RequestContext,
    id_: UUID,
) -> bytes:
    """Fetch the stream with the given ID

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the stream to fetch

    Returns:
    Stream data as requested
    """

    path = "/v1/api/ulv2/datacatalog/stream/:id"
    path.replace(":id", str(id_), 1)

    params = dict()
    headers = dict()
    headers["Accept"] = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet";

    res = ctx.get(path, params=params, headers=headers)
    return res

def stream_get_json(
    ctx: RequestContext,
    id_: UUID,
) -> bytes:
    """Fetch the stream with the given ID

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the stream to fetch

    Returns:
    Stream data as requested
    """

    path = "/v1/api/ulv2/datacatalog/stream/:id"
    path.replace(":id", str(id_), 1)

    params = dict()
    headers = dict()
    headers["Accept"] = "application/json";

    res = ctx.get(path, params=params, headers=headers)
    return res

def stream_get_text(
    ctx: RequestContext,
    id_: UUID,
) -> bytes:
    """Fetch the stream with the given ID

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the stream to fetch

    Returns:
    Stream data as requested
    """

    path = "/v1/api/ulv2/datacatalog/stream/:id"
    path.replace(":id", str(id_), 1)

    params = dict()
    headers = dict()
    headers["Accept"] = "text/plain";

    res = ctx.get(path, params=params, headers=headers)
    return res

def stream_get_html(
    ctx: RequestContext,
    id_: UUID,
) -> bytes:
    """Fetch the stream with the given ID

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the stream to fetch

    Returns:
    Stream data as requested
    """

    path = "/v1/api/ulv2/datacatalog/stream/:id"
    path.replace(":id", str(id_), 1)

    params = dict()
    headers = dict()
    headers["Accept"] = "text/html";

    res = ctx.get(path, params=params, headers=headers)
    return res

def stream_put_arrow(
    ctx: RequestContext,
    id_: UUID,
    subcollection: Optional[str],
    data: List[RecordBatch],
) -> None:
    """Append data, in Apache Arrow format, to the specified stream

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the stream to append data to
    subcollection: Optional[str] -- Subcollection to append data to, if necessary
    data: List[RecordBatch] -- The Arrow record batches to append
    """

    path = "/v1/api/ulv2/datacatalog/stream/:id"
    path.replace(":id", str(id_), 1)

    params = dict()
    if subcollection is not None:
        params["subcollection"] = subcollection

    headers = dict()
    if len(data) == 0:
        raise ValueError("cannot provide zero record batches; at least one required to get the schema")
    body_schema = data[0].schema
    body_sink = BufferOutputStream()
    body_writer = RecordBatchStreamWriter(body_sink, body_schema)
    for batch in data:
        body_writer.write_batch(batch)
    body_writer.close()
    body = body_sink.getvalue().to_pybytes()
    ctx.put(path, body=body, mimetype="application/vnd.apache.arrow.stream", params=params, headers=headers)
    return

def stream_put_diffstream(
    ctx: RequestContext,
    id_: UUID,
    subcollection: Optional[str],
    data: DiffStream,
) -> None:
    """Append a diffstream to the specified stream

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the stream to append data to
    subcollection: Optional[str] -- Subcollection to append data to, if necessary
    data: DiffStream -- The Arrow record batches to append
    """

    path = "/v1/api/ulv2/datacatalog/stream/:id"
    path.replace(":id", str(id_), 1)

    params = dict()
    if subcollection is not None:
        params["subcollection"] = subcollection

    headers = dict()
    body = data.to_bytes()
    ctx.put(path, body=body, mimetype="application/octet-stream", params=params, headers=headers)
    return

def stream_put_json(
    ctx: RequestContext,
    id_: UUID,
    subcollection: Optional[str],
    data: List[Dict[str, Any]],
) -> None:
    """Append JSON data to the specified stream

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the stream to append data to
    subcollection: Optional[str] -- Subcollection to append data to, if necessary
    data: List[Dict[str, Any]] -- The Arrow record batches to append
    """

    path = "/v1/api/ulv2/datacatalog/stream/:id"
    path.replace(":id", str(id_), 1)

    params = dict()
    if subcollection is not None:
        params["subcollection"] = subcollection

    headers = dict()
    body_list = []
    for item in data:
        body_var = json.dumps(item)
        body_list.append(body_var)
    body = json.dumps(body_list)
    ctx.put(path, body=body, mimetype="application/json", params=params, headers=headers)
    return

def generate_metadata(
    ctx: RequestContext,
    id_: UUID,
) -> Metadata:
    """Generate metadata for the specified stream

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the stream to generate metadata for

    Returns:
    The metadata as generated from the stream data
    """

    path = "/v1/api/ulv2/datacatalog/stream/:id/generated/metadata"
    path.replace(":id", str(id_), 1)

    params = dict()
    headers = dict()
    res = ctx.get(path, params=params, headers=headers)
    return Metadata.from_bytes(res)

def update_metadata(
    ctx: RequestContext,
    id_: UUID,
    metadata: Optional[Metadata],
) -> None:
    """Given a stream ID and metadata, update the stream metadata to a combination of:
    - the existing metadata
    - the provided metadata
    - the generated metadata
    Also, update the stream object to point to the updated metadata and to have an updated schema.

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the stream to update metadata for
    metadata: Optional[Metadata] -- The metadata to update the stream with
    """

    path = "/v1/api/ulv2/datacatalog/stream/:id/metadata"
    path.replace(":id", str(id_), 1)

    params = dict()
    headers = dict()
    body = None;
    if metadata is not None:
        body = metadata.to_bytes()
    ctx.post(path, body=body, mimetype="application/octet-stream", params=params, headers=headers)
    return

def stream_compact(
    ctx: RequestContext,
    id_: UUID,
    subcollection: Optional[str],
) -> None:
    """Compact the specified stream

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the stream to compact
    subcollection: Optional[str] -- Subcollection to append data to, if necessary
    """

    path = "/v1/api/ulv2/datacatalog/stream/:id/compact"
    path.replace(":id", str(id_), 1)

    params = dict()
    if subcollection is not None:
        params["subcollection"] = subcollection

    headers = dict()
    body = None
    ctx.post(path, body=body, mimetype="text/plain", params=params, headers=headers)
    return

def table_row_history(
    ctx: RequestContext,
    id_: UUID,
    row: UUID,
) -> History:
    """Fetch the history of a row in a table

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the table to fetch the row history from
    row: UUID -- The ID of the row to fetch the history for

    Returns:
    The history of the row
    """

    path = "/v1/api/ulv2/datacatalog/table/:id/history/:row"
    path.replace(":id", str(id_), 1)
    path.replace(":row", str(row), 1)

    params = dict()
    headers = dict()
    res = ctx.get(path, params=params, headers=headers)
    return History.from_bytes(res)

def table_history(
    ctx: RequestContext,
    id_: UUID,
) -> History:
    """Fetch the history of a table

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the table to fetch the history from

    Returns:
    The history of the table
    """

    path = "/v1/api/ulv2/datacatalog/table/:id/history"
    path.replace(":id", str(id_), 1)

    params = dict()
    headers = dict()
    res = ctx.get(path, params=params, headers=headers)
    return History.from_bytes(res)

def get_table_attachments_directory(
    ctx: RequestContext,
    id_: UUID,
    row: UUID,
) -> ObjectId:
    """Fetch the directory ID for a row's file attachments location

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the table to fetch the attachments directory ID from
    row: UUID -- The ID of the row to fetch the attachments directory ID for

    Returns:
    The directory ID for the row's attachments
    """

    path = "/v1/api/ulv2/datacatalog/table/:id/attachments/:row"
    path.replace(":id", str(id_), 1)
    path.replace(":row", str(row), 1)

    params = dict()
    headers = dict()
    res = ctx.get(path, params=params, headers=headers)
    return ObjectId.from_bytes(res)

def get_or_create_table_attachments_directory(
    ctx: RequestContext,
    id_: UUID,
    row: UUID,
) -> ObjectId:
    """Fetch the directory ID for a row's file attachments location, creating it if it doesn't exist

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the table to fetch the attachments directory ID from
    row: UUID -- The ID of the row to fetch the attachments directory ID for

    Returns:
    The directory ID for the row's attachments
    """

    path = "/v1/api/ulv2/datacatalog/table/:id/attachments/:row"
    path.replace(":id", str(id_), 1)
    path.replace(":row", str(row), 1)

    params = dict()
    headers = dict()
    body = None
    res = ctx.post(path, body=body, mimetype="text/plain", params=params, headers=headers)
    return ObjectId.from_bytes(res)

def create_table(
    ctx: RequestContext,
    id_: UUID,
    new_table: NewTable,
) -> ObjectId:
    """Create a new table in the provided directory

    Arguments:
    ctx: RequestContext -- A request context object
    id_: UUID -- The ID of the directory to create the table in
    new_table: NewTable -- New table creation details

    Returns:
    The ID of the newly created table
    """

    path = "/v1/api/ulv2/datacatalog/table/:id"
    path.replace(":id", str(id_), 1)

    params = dict()
    headers = dict()
    body = new_table.to_bytes()
    res = ctx.post(path, body=body, mimetype="application/octet-stream", params=params, headers=headers)
    return ObjectId.from_bytes(res)

def query_arrow(
    ctx: RequestContext,
    query: Query,
) -> List[RecordBatch]:
    """Query the datacatalog, returning data in Apache Arrow IPC Stream format

    Arguments:
    ctx: RequestContext -- A request context object
    query: Query -- The query to execute

    Returns:
    The result of the query
    """

    path = "/v1/api/ulv2/datacatalog/query"
    params = dict()
    headers = dict()
    headers["Accept"] = "application/vnd.apache.arrow.stream";

    body = query.to_bytes()
    res = ctx.post(path, body=body, mimetype="application/octet-stream", params=params, headers=headers)
    reader = RecordBatchStreamReader(res)
    return reader.read_all().to_batches()

def query_parquet(
    ctx: RequestContext,
    query: Query,
) -> bytes:
    """Query the datacatalog, returning data in Apache Parquet format

    Arguments:
    ctx: RequestContext -- A request context object
    query: Query -- The query to execute

    Returns:
    The result of the query
    """

    path = "/v1/api/ulv2/datacatalog/query"
    params = dict()
    headers = dict()
    headers["Accept"] = "application/vnd.apache.parquet";

    body = query.to_bytes()
    res = ctx.post(path, body=body, mimetype="application/octet-stream", params=params, headers=headers)
    return res

def query_csv(
    ctx: RequestContext,
    query: Query,
) -> bytes:
    """Query the datacatalog, returning data in CSV format

    Arguments:
    ctx: RequestContext -- A request context object
    query: Query -- The query to execute

    Returns:
    The result of the query
    """

    path = "/v1/api/ulv2/datacatalog/query"
    params = dict()
    headers = dict()
    headers["Accept"] = "text/csv";

    body = query.to_bytes()
    res = ctx.post(path, body=body, mimetype="application/octet-stream", params=params, headers=headers)
    return res

def query_xlsx(
    ctx: RequestContext,
    query: Query,
) -> bytes:
    """Query the datacatalog, returning data in Excel (XLSX) format

    Arguments:
    ctx: RequestContext -- A request context object
    query: Query -- The query to execute

    Returns:
    The result of the query
    """

    path = "/v1/api/ulv2/datacatalog/query"
    params = dict()
    headers = dict()
    headers["Accept"] = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet";

    body = query.to_bytes()
    res = ctx.post(path, body=body, mimetype="application/octet-stream", params=params, headers=headers)
    return res

def query_json(
    ctx: RequestContext,
    query: Query,
) -> bytes:
    """Query the datacatalog, returning data JSON

    Arguments:
    ctx: RequestContext -- A request context object
    query: Query -- The query to execute

    Returns:
    The result of the query
    """

    path = "/v1/api/ulv2/datacatalog/query"
    params = dict()
    headers = dict()
    headers["Accept"] = "application/json";

    body = query.to_bytes()
    res = ctx.post(path, body=body, mimetype="application/octet-stream", params=params, headers=headers)
    return res

def query_text(
    ctx: RequestContext,
    query: Query,
) -> bytes:
    """Query the datacatalog, returning data in plain text

    Arguments:
    ctx: RequestContext -- A request context object
    query: Query -- The query to execute

    Returns:
    The result of the query
    """

    path = "/v1/api/ulv2/datacatalog/query"
    params = dict()
    headers = dict()
    headers["Accept"] = "text/plain";

    body = query.to_bytes()
    res = ctx.post(path, body=body, mimetype="application/octet-stream", params=params, headers=headers)
    return res

def query_html(
    ctx: RequestContext,
    query: Query,
) -> bytes:
    """Query the datacatalog, returning data in HTML

    Arguments:
    ctx: RequestContext -- A request context object
    query: Query -- The query to execute

    Returns:
    The result of the query
    """

    path = "/v1/api/ulv2/datacatalog/query"
    params = dict()
    headers = dict()
    headers["Accept"] = "text/html";

    body = query.to_bytes()
    res = ctx.post(path, body=body, mimetype="application/octet-stream", params=params, headers=headers)
    return res
