# Copyright (c), CommunityLogiq Software
# 
# THIS FILE IS AUTOGENERATED, DO NOT EDIT

from dataclasses import dataclass
from enum import Enum
from flatbuffers.table import Table
from flatbuffers.builder import Builder
from flatbuffers.util import RemoveSizePrefix
from typing import Union, List, Optional, Self, Tuple
from .Schema import (
    Binary,
    Bool,
    Buffer,
    Date,
    DateUnit,
    Decimal,
    DictionaryEncoding,
    DictionaryKind,
    Duration,
    Endianness,
    Feature,
    Field,
    FixedSizeBinary,
    FixedSizeList,
    FloatingPoint,
    Int,
    Interval,
    IntervalUnit,
    KeyValue,
    LargeBinary,
    LargeList,
    LargeUtf8,
    List_,
    Map,
    MetadataVersion,
    Null,
    Precision,
    Schema,
    Struct_,
    Time,
    TimeUnit,
    Timestamp,
    Type,
    Union_,
    UnionMode,
    Utf8,
)
from .id import (
    B2cId,
    ColumnGroupId,
    ContentId,
    DataStateId,
    GenericId,
    GraphNodeId,
    ObjectId,
    ObjectNamespace,
    StreamId,
)
from .generated.B2cId import B2cId as FbsB2cId
from .generated.Binary import Binary as FbsBinary
from .generated.Bool import Bool as FbsBool
from .generated.Buffer import Buffer as FbsBuffer
from .generated.ColumnGroupId import ColumnGroupId as FbsColumnGroupId
from .generated.ContentId import ContentId as FbsContentId
from .generated.DataStateId import DataStateId as FbsDataStateId
from .generated.Date import Date as FbsDate
from .generated.Decimal import Decimal as FbsDecimal
from .generated.DictionaryEncoding import DictionaryEncoding as FbsDictionaryEncoding
from .generated.Duration import Duration as FbsDuration
from .generated.Field import Field as FbsField
from .generated.FixedSizeBinary import FixedSizeBinary as FbsFixedSizeBinary
from .generated.FixedSizeList import FixedSizeList as FbsFixedSizeList
from .generated.FloatingPoint import FloatingPoint as FbsFloatingPoint
from .generated.GenericId import GenericId as FbsGenericId
from .generated.GraphNodeId import GraphNodeId as FbsGraphNodeId
from .generated.Int import Int as FbsInt
from .generated.Interval import Interval as FbsInterval
from .generated.KeyValue import KeyValue as FbsKeyValue
from .generated.LargeBinary import LargeBinary as FbsLargeBinary
from .generated.LargeList import LargeList as FbsLargeList
from .generated.LargeUtf8 import LargeUtf8 as FbsLargeUtf8
from .generated.List import List as FbsList
from .generated.Map import Map as FbsMap
from .generated.Null import Null as FbsNull
from .generated.ObjectId import ObjectId as FbsObjectId
from .generated.Schema import Schema as FbsSchema
from .generated.Stream import Stream as FbsStream
from .generated.StreamId import StreamId as FbsStreamId
from .generated.Struct_ import Struct_ as FbsStruct_
from .generated.Time import Time as FbsTime
from .generated.Timestamp import Timestamp as FbsTimestamp
from .generated.Union import Union as FbsUnion
from .generated.Utf8 import Utf8 as FbsUtf8
from .generated.Type import Type as FbsType

class AxisType(Enum):
    AXIS_TIMESTAMP = 0

class FormatFlags(Enum):
    OmitNodeId = 1
    WithDescription = 2
    WithGeom = 4

class StreamFlags(Enum):
    Dynamic = 1


@dataclass
class Stream:
    """ A Stream is an instance of a source. The main difference is the parameters
     field is not a ParameterDesc descriptor object but the actual, serialized
     parameter values.

     Code performing the operation on the source will be able to construct a
     stream object from this description and downstream code will be able to
     read from it.
    """

    flags: "int"

    metadata: Optional["ObjectId"]

    metadata_revision: Optional["ContentId"]

    options: Optional["List[int]"]

    parameters: Optional["List[int]"]

    schema: "Schema"

    substreams: Optional["List[ObjectId]"]

    url: "str"

    @classmethod
    def from_fbs(cls, o: FbsStream) -> Self:
        flags = o.Flags()
        metadata = None
        metadata_obj = o.Metadata()
        if metadata_obj is not None:
            metadata = ObjectId.from_fbs(metadata_obj)
        metadata_revision = None
        metadata_revision_obj = o.MetadataRevision()
        if metadata_revision_obj is not None:
            metadata_revision = ContentId.from_fbs(metadata_revision_obj)
        options = list()
        if not o.OptionsIsNone():
            for i in range(o.OptionsLength()):
                options.append(o.Options(i))
        parameters = list()
        if not o.ParametersIsNone():
            for i in range(o.ParametersLength()):
                parameters.append(o.Parameters(i))
        schema_obj = o.Schema()
        if schema_obj is not None:
            schema = Schema.from_fbs(schema_obj)
        else:
            raise ValueError("Schema is required")
        substreams = list()
        if not o.SubstreamsIsNone():
            for i in range(o.SubstreamsLength()):
                substreams_val = None
                substreams_obj = o.Substreams(i)
                if substreams_obj is not None:
                    substreams_val = ObjectId.from_fbs(substreams_obj)
                substreams.append(substreams_val)
        url_str = o.Url()
        assert url_str is not None
        url = url_str.decode('utf-8')
        return cls(flags, metadata, metadata_revision, options, parameters, schema, substreams, url)

    @classmethod
    def from_bytes(cls, data: bytes) -> Self:
        deprefixed = RemoveSizePrefix(data, 0)
        o = FbsStream.GetRootAs(deprefixed[0], deprefixed[1])
        return cls.from_fbs(o)

    def serialize_to(self, builder: Builder) -> int:
        from .generated.Stream import (
            Start,
            AddFlags,
            AddMetadata,
            AddMetadataRevision,
            AddOptions,
            StartOptionsVector,
            AddParameters,
            StartParametersVector,
            AddSchema,
            AddSubstreams,
            StartSubstreamsVector,
            AddUrl,
            End,
        )
        metadata_offset = None
        if self.metadata is not None:
            metadata_offset = self.metadata.serialize_to(builder)
        metadata_revision_offset = None
        if self.metadata_revision is not None:
            metadata_revision_offset = self.metadata_revision.serialize_to(builder)
        options_offset = None
        if self.options is not None:
            StartOptionsVector(builder, len(self.options))
            for i in reversed(range(len(self.options))):
                builder.PrependUint8(self.options[i])
            options_offset = builder.EndVector()
        parameters_offset = None
        if self.parameters is not None:
            StartParametersVector(builder, len(self.parameters))
            for i in reversed(range(len(self.parameters))):
                builder.PrependUint8(self.parameters[i])
            parameters_offset = builder.EndVector()
        schema_offset = self.schema.serialize_to(builder)
        substreams_offset = None
        if self.substreams is not None:
            substreams_offsets = list()
            for value in self.substreams:
                substreams_offsets.append(value.serialize_to(builder))
            StartSubstreamsVector(builder, len(self.substreams))
            for i in reversed(range(len(self.substreams))):
                builder.PrependUOffsetTRelative(substreams_offsets[i])
            substreams_offset = builder.EndVector()
        url_offset = builder.CreateString(self.url)
        
        Start(builder)
        AddFlags(builder, self.flags)
        if metadata_offset is not None:
            AddMetadata(builder, metadata_offset)
        if metadata_revision_offset is not None:
            AddMetadataRevision(builder, metadata_revision_offset)
        if options_offset is not None:
            AddOptions(builder, options_offset)
        if parameters_offset is not None:
            AddParameters(builder, parameters_offset)
        AddSchema(builder, schema_offset)
        if substreams_offset is not None:
            AddSubstreams(builder, substreams_offset)
        AddUrl(builder, url_offset)
        return End(builder)

    def to_bytes(self) -> bytes:
        builder = Builder(0)
        offset = self.serialize_to(builder)
        builder.FinishSizePrefixed(offset)
        return builder.Output()

    @classmethod
    def make_default(cls) -> Self:
        flags = 0
        metadata = ObjectId.make_default()
        metadata_revision = ContentId.make_default()
        options = []
        parameters = []
        schema = Schema.make_default()
        substreams = []
        url = ""
        return cls(flags, metadata, metadata_revision, options, parameters, schema, substreams, url)

    def __eq__(self, other) -> bool:
        eq = True
        eq = eq and self.flags == other.flags
        eq = eq and self.metadata == other.metadata
        eq = eq and self.metadata_revision == other.metadata_revision
        self_options = self.options
        other_options = other.options
        if self_options is not None and other_options is not None:
            if len(self_options) != len(other_options):
                return False
            for i in range(len(self_options)):
                eq = eq and self_options[i] == other_options[i]
        elif self_options is not None and other_options is None:
            return False
        elif self_options is None and other_options is not None:
            return False
        self_parameters = self.parameters
        other_parameters = other.parameters
        if self_parameters is not None and other_parameters is not None:
            if len(self_parameters) != len(other_parameters):
                return False
            for i in range(len(self_parameters)):
                eq = eq and self_parameters[i] == other_parameters[i]
        elif self_parameters is not None and other_parameters is None:
            return False
        elif self_parameters is None and other_parameters is not None:
            return False
        eq = eq and self.schema == other.schema
        self_substreams = self.substreams
        other_substreams = other.substreams
        if self_substreams is not None and other_substreams is not None:
            if len(self_substreams) != len(other_substreams):
                return False
            for i in range(len(self_substreams)):
                eq = eq and self_substreams[i] == other_substreams[i]
        elif self_substreams is not None and other_substreams is None:
            return False
        elif self_substreams is None and other_substreams is not None:
            return False
        eq = eq and self.url == other.url

        return eq
